{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame III\n",
    "\n",
    "Los objetivos de aprendizaje son:\n",
    "\n",
    "1. Valores Duplicados\n",
    "    + .duplicate()\n",
    "    + .drop_duplicates()\n",
    "    + .unique()\n",
    "    + .nunique()\n",
    "2. Random Samples\n",
    "    + Registros\n",
    "    + Columnas\n",
    "3. Group by\n",
    "    + get_group()\n",
    "    + .agg()\n",
    "    + Multiples columnas\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Valores Duplicados\n",
    "\n",
    "Pandas cuenta con un grupo de métodos que son bastante útiles para gestionar información duplicada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./Data/pandas/employees.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El DataFrame contiene algunos campos que evidentemente son del tipo fecha, ¿Cómo los habrá interpretado la función `read_csv()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ha interpretado como `str`. Podemos indicar a la función qué columnas debe interpretar como fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/pandas/employees.csv\", parse_dates = ['Start Date', 'Last Login Time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Mejor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('First Name', inplace = True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duplicated\n",
    "\n",
    "El método [`.duplicated()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html) detecta datos duplicados, los  parámetros importantes son:\n",
    "\n",
    "* subset: Los nombres de las columnas sobre los que verificaremos la condición de duplicado. \n",
    "* keep:\n",
    "    + `\"first\"`: Marcará como True a los registro duplicados, salvo al primero.\n",
    "    + `\"last\"`: Marcará como True a los registro duplicados, salvo a último.\n",
    "    + `False`: Marcará como True a todas las ocurrencias de duplicados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['First Name', 'Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    df.duplicated(\n",
    "        subset = [\"First Name\", \"Gender\"], keep = False\n",
    "    )\n",
    "].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    df.duplicated(\n",
    "        subset = [\"First Name\", \"Gender\"], keep = \"first\"\n",
    "    )\n",
    "].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    df.duplicated(\n",
    "        subset = [\"First Name\", \"Gender\"], keep = \"last\"\n",
    "    )\n",
    "].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop_duplicates \n",
    "\n",
    "Antes de borrar los elementos duplicados en un `DataFrame` es importante ivestigar por qué están ahí.\n",
    "\n",
    "En cualquier caso, si ya entendimos por qué tenemos duplicados y estamos seguros que queremos borrarlos, podemos usar el método [`.drop_duplicates()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset = ['First Name', 'Gender'], keep = \"first\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique()\n",
    "\n",
    "El método `.unique()` nos regresa los posibles valores que existen en una columna de un `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nunique()\n",
    "\n",
    "El método `.nunique()`  aplicado sobre la columna de un `DataFame`, nos regresa cuántos valores únicos existen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos configurarlo para que cuente los `NaN`s como otro tipo de valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].nunique(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Samples\n",
    "\n",
    "Podemos generar muestras aleatorias con el método `.sample()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac = .7).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac = .7).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac = .7, random_state = 101).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac = .7, random_state = 101).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3, axis = 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Group by\n",
    "\n",
    "Nos ayuda a agregar los datos para poder analizar tendencias.\n",
    "\n",
    "Para esta sección usaremos un `DataFrame` que contiene información de las 1000 empresas más grandes, según datos de [fortune](https://fortune.com/) correspondientes al 2016.\n",
    "\n",
    "### .gropuby()\n",
    "\n",
    "\n",
    "\n",
    "El método [`.groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune = pd.read_csv(\"./Data/pandas/fortune1000.csv\")\n",
    "fortune.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = fortune.groupby(by = ['Sector'])\n",
    "sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `.groupby()` nos regresa un objeto de la clase `DataFrameGroupby`.\n",
    "\n",
    "¿Qué es exactamente este objeto? es una especie de extra índice que dice a Pandas dónde mirar cuando más adelante se le pidan hacer cierto tipo de operaciones de agregación.\n",
    "\n",
    "Esto quedará más claro con un ejemplo de una llamada al atributo `grups`, que nos regresará un diccionario en donde:\n",
    "\n",
    "* `keys`: Los valores de la variable que usamos en el método`.groupby()`.\n",
    "* `values`: son los ínices que contienen los registros de cada valor de la variable agrupadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sector.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune.loc[[23, 44, 59, 87, 117]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiéramos seleccionar todos los registros tal que `Sector == \"Aerospace & Defense\"`, podríamos hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune.loc[sector.groups['Aerospace & Defense']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero esto es más directo con el método `.get_group()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sector.get_group('Aerospace & Defense').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que queremos saber en qué sector la media de `Revenue` es más alta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sector['Revenue'].mean(),2).sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O quizás queremos saber el percentil 0.95 de la variable `Profits` por Sector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sector['Profits'].quantile(0.95).sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo realizar operaciones de agregación por múltiples columnas manteniendo un formato de `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fortune.groupby(\n",
    "    by = ['Sector', 'Industry']\n",
    ")['Profits'].max().to_frame().reset_index().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agg\n",
    "\n",
    "El método [`.agg()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html), aplicado sobre un `DataFrameGroupBy` nos ofrece una mayo flexibilidad para realizar operaciones de agregación, veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortune.groupby(by = ['Sector']).agg(\n",
    "    mean_profit = ('Profits', lambda x: round(np.mean(x),2)),\n",
    "    per_95_profit = ('Profits', lambda x: np.percentile(x,95))\n",
    "    ).reset_index().sort_values('mean_profit', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteración sobre Grupos\n",
    "\n",
    "Supongamos que nos interesa saber cuáles son las compañías con el mayor margen de ganancias por sector, no cuál es el máximo margen de ganancias por sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = fortune.groupby(by = 'Sector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank2_bysector = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grupo, data in sector:\n",
    "    rank2_bysector.append(\n",
    "        data.nlargest(2, \"Profits\")\n",
    "    )\n",
    "pd.concat(rank2_bysector).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
